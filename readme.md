# Assistant Acad√©mique 3.0

Un assistant de recherche acad√©mique intelligent, propuls√© par LangGraph, LangChain et les grands mod√®les de langage.

## üöÄ Fonctionnalit√©s

- **Moteur d'Intelligence Hybride**: Choix entre Ollama (local) et Claude API (cloud)
- **Classification Automatique de Requ√™tes**: D√©tection intelligente du type de question pos√©e
- **Workflow Optimis√©**: Architecture LangGraph pour un traitement s√©quentiel et conditionnel
- **Visualisation du Raisonnement**: Exploration visuelle du cheminement de l'assistant
- **Mode Verbeux**: D√©tails complets du processus de r√©flexion
- **Interface Double**: Ligne de commande ou application web Streamlit
- **Analyse de Documents PDF**: Extraction et exploration de contenu acad√©mique

## üìã Pr√©requis

- Python 3.9 ou sup√©rieur
- [Ollama](https://ollama.com/download) (pour les mod√®les locaux)
- Cl√© API Anthropic (pour Claude)

## üîß Installation

1. **Cloner le d√©p√¥t**

```bash
git clone https://github.com/votre-repo/academic-assistant.git
cd academic-assistant
```

2. **Installer les d√©pendances**

Vous pouvez utiliser le script de lancement qui installera automatiquement les d√©pendances requises:

```bash
python launch.py
```

Ou les installer manuellement:

```bash
pip install langchain langchain_community langchain_huggingface langchain_chroma
pip install langchain_text_splitters langchain_ollama chromadb langgraph
pip install streamlit plotly pyvis networkx sentence-transformers matplotlib pandas pydantic
```

3. **Installer et configurer Ollama** (Pour les mod√®les locaux)

Suivez les instructions sur [ollama.com/download](https://ollama.com/download)

T√©l√©chargez les mod√®les que vous souhaitez utiliser:

```bash
ollama pull deepseek-r1:8b
ollama pull llama3.1:8b
```

## üîë Configuration de la cl√© API Anthropic

Pour utiliser Claude, vous devez configurer une cl√© API Anthropic. Plusieurs m√©thodes sont disponibles :

1. **Variable d'environnement**:
   - D√©finissez `ANTHROPIC_API_KEY` ou `CLAUDE_API_KEY` dans votre environnement
   - Exemple: `export ANTHROPIC_API_KEY=votre_cl√©_api_ici`

2. **Fichier de configuration global**:
   - Cr√©ez un fichier `.academic_assistant_config` dans votre r√©pertoire utilisateur
   - Ajoutez la ligne: `ANTHROPIC_API_KEY=votre_cl√©_api_ici`

3. **Fichier de configuration local**:
   - Cr√©ez un fichier `.env` dans le r√©pertoire du projet (vous pouvez utiliser `.env.example` comme mod√®le)
   - Ajoutez la ligne: `ANTHROPIC_API_KEY=votre_cl√©_api_ici`

4. **Interface Streamlit**:
   - Saisissez votre cl√© API dans l'interface web
   - Elle sera automatiquement enregistr√©e dans l'environnement pour les utilisations futures

L'assistant cherchera la cl√© dans cet ordre et l'utilisera automatiquement quand vous s√©lectionnez Claude comme mod√®le.

## üíª Utilisation

### Lancer l'application

```bash
python launch.py
```

Vous serez invit√© √† choisir entre l'interface en ligne de commande ou l'interface web Streamlit.

### Lancer directement l'interface en ligne de commande

```bash
python launch.py cli --docs ./votre-dossier-documents --model-type ollama --model-name deepseek-r1:8b
```

Options disponibles:
- `--docs`: Dossier contenant les documents PDF (par d√©faut: ./documents)
- `--model-type`: Type de mod√®le (ollama ou claude)
- `--model-name`: Nom du mod√®le sp√©cifique
- `--verbose`: Mode verbeux

### Lancer directement l'interface web Streamlit

```bash
python launch.py web --docs ./votre-dossier-documents
```

L'interface web sera accessible √† l'adresse [http://localhost:8501](http://localhost:8501)

## üß† Types de Requ√™tes Support√©s

- **standard**: Recherche d'informations sp√©cifiques et pr√©cises
- **synthesis**: Demande de synth√®se ou r√©sum√© sur un th√®me/sujet
- **research_question**: Identification de questions ou probl√©matiques de recherche
- **objective**: Recherche d'objectifs ou buts d'une √©tude
- **conclusion**: Extraction de conclusions ou r√©sultats d'une √©tude
- **elaboration**: √âlaboration complexe bas√©e sur plusieurs documents
- **comparison**: Comparaison entre diff√©rentes √©tudes ou approches
- **methodology**: Analyse de la m√©thodologie utilis√©e dans une √©tude
- **auto**: D√©tection automatique du type de requ√™te (par d√©faut)

## üìÑ Structure du Projet

- `academic_assistant.py`: Module principal avec l'impl√©mentation LangGraph
- `model_connectors.py`: Connecteurs pour les diff√©rents mod√®les (Ollama, Claude)
- `query_classifier.py`: Classification automatique des types de requ√™tes
- `streamlit_interface.py`: Interface utilisateur web avec Streamlit
- `launch.py`: Script de lancement unifi√©

## üìä Visualisation du Workflow

L'assistant utilise un workflow LangGraph structur√© avec les √©tapes suivantes:

1. **Analyse de la question**: D√©termination du type de requ√™te
2. **Reformulation**: Optimisation de la requ√™te pour la recherche
3. **R√©cup√©ration de documents**: Recherche dans la base de connaissances
4. **√âvaluation de pertinence**: Analyse de la qualit√© des r√©sultats
5. **Affinement de recherche** (conditionnel): Am√©lioration des r√©sultats si n√©cessaire
6. **G√©n√©ration de r√©ponse**: Production d'une r√©ponse acad√©mique pr√©cise

## üìö Ajouter des Documents

Placez vos fichiers PDF dans le dossier `documents` (ou celui sp√©cifi√© via l'option `--docs`).

L'assistant indexera automatiquement ces documents lors de la premi√®re ex√©cution.

## üîÑ Mise √† Jour de la Base de Connaissances

Pour r√©indexer les documents (apr√®s avoir ajout√© de nouveaux fichiers):

- **Interface CLI**: Utilisez l'option `--reindex` lors du lancement
- **Interface Web**: Cochez la case "R√©indexer les documents" dans la barre lat√©rale

## üõ†Ô∏è Configuration Avanc√©e

### Variables d'Environnement

- `ANTHROPIC_API_KEY`: Cl√© API pour Claude (principale)
- `CLAUDE_API_KEY`: Alternative pour la cl√© API Claude
- `LANGGRAPH_API_KEY`: Cl√© API pour la visualisation LangGraph (facultatif)
- `ENABLE_TRACING`: Activer le tra√ßage LangGraph (true/false)

## üìù Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

## üôè Remerciements

- [LangChain](https://www.langchain.com/) pour le framework d'orchestration
- [LangGraph](https://www.langchain.com/langgraph) pour le moteur de workflow
- [Anthropic](https://www.anthropic.com/) pour Claude
- [Ollama](https://ollama.com/) pour l'ex√©cution locale de mod√®les